{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from desci_sense.shared_functions.init import init_multi_chain_parser_config\n",
    "from desci_sense.evaluation.Evaluation_benchmark import TwitterEval\n",
    "from desci_sense.shared_functions.parsers.multi_chain_parser import MultiChainParser\n",
    "from desci_sense.evaluation.utils import get_dataset, obj_to_json, obj_str_to_dict\n",
    "from desci_sense.shared_functions.dataloaders import (\n",
    "    scrape_post,\n",
    "    convert_text_to_ref_post,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = init_multi_chain_parser_config(llm_type='mistralai/mixtral-8x7b',\n",
    "                                        post_process_type=\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-05-28 13:21:04.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.multi_chain_parser\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mInitializing MultiChainParser. PostProcessType=combined\u001b[0m\n",
      "\u001b[32m2024-05-28 13:21:04.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.multi_chain_parser\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mInitializing post parsers...\u001b[0m\n",
      "\u001b[32m2024-05-28 13:21:04.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.post_parser_chain\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mInitializing parser chain 'multi_refs_tagger' \u001b[0m\n",
      "\u001b[32m2024-05-28 13:21:04.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.post_parser_chain\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mInitializing parser chain 'topics' \u001b[0m\n",
      "\u001b[32m2024-05-28 13:21:04.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.post_parser_chain\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mInitializing parser chain 'keywords' \u001b[0m\n",
      "\u001b[32m2024-05-28 13:21:04.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.post_parser_chain\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mInitializing parser chain 'hashtags' \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "multi_chain_parser = MultiChainParser(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading wandb dataset to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/shaharorielkagan/sensemakers/nlp/notebooks/wandb/run-20240520_193247-g39xcxp1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/common-sense-makers/testing/runs/g39xcxp1' target=\"_blank\">curious-valley-242</a></strong> to <a href='https://wandb.ai/common-sense-makers/testing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/common-sense-makers/testing' target=\"_blank\">https://wandb.ai/common-sense-makers/testing</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/common-sense-makers/testing/runs/g39xcxp1' target=\"_blank\">https://wandb.ai/common-sense-makers/testing/runs/g39xcxp1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path is /Users/shaharorielkagan/sensemakers/nlp/notebooks/artifacts/labeled_tweets_no_threads:v1\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "#TODO move from testing\n",
    "run = wandb.init(project=\"testing\", job_type=\"evaluation\")\n",
    "\n",
    "# get artifact path\n",
    "\n",
    "dataset_artifact_id = (\n",
    "        'common-sense-makers/filter_evaluation/labeled_tweets_no_threads:v1'\n",
    "    )\n",
    "\n",
    "# set artifact as input artifact\n",
    "dataset_artifact = run.use_artifact(dataset_artifact_id)\n",
    "\n",
    "# initialize table path\n",
    "# add the option to call table_path =  arguments.get('--dataset')\n",
    "\n",
    "# download path to table\n",
    "a_path = dataset_artifact.download()\n",
    "print(\"The path is\",a_path)\n",
    "\n",
    "# get dataset file name\n",
    "\n",
    "table_path = Path(f\"{a_path}/labeled_data_table_no_threads.table.json\")\n",
    "\n",
    "\n",
    "# return the pd df from the table\n",
    "#remember to remove the head TODO\n",
    "df = get_dataset(table_path).head(150)\n",
    "\n",
    "table_path = Path(f\"{a_path}/handles_chart.table.json\")\n",
    "\n",
    "df_handles = get_dataset(table_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:18<00:00,  8.11it/s]\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_text(text):\n",
    "    return convert_text_to_ref_post(text)\n",
    "\n",
    "# Assuming df['Text'] is your DataFrame column\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    inputs = list(tqdm(executor.map(process_text, df['Text']), total=len(df['Text'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = scrape_post('https://x.com/rtk254/status/1741841607421263966')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-04 12:19:46.811\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 1\u001b[0m\n",
      "\u001b[32m2024-06-04 12:19:46.815\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://paragraph.xyz/@sense-nets/2-project-plan\u001b[0m\n",
      "\u001b[32m2024-06-04 12:19:46.827\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 1\u001b[0m\n",
      "\u001b[32m2024-06-04 12:19:46.828\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m104\u001b[0m - \u001b[34m\u001b[1mskipping citoid for https://twitter.com/i/status/1732044124508008571\u001b[0m\n",
      "\u001b[32m2024-06-04 12:19:46.831\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 1\u001b[0m\n",
      "\u001b[32m2024-06-04 12:19:46.834\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://paragraph.xyz/@sense-nets/sense-nets-intro\u001b[0m\n",
      "\u001b[32m2024-06-04 12:19:47.869\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.multi_chain_parser\u001b[0m:\u001b[36mprocess_ref_post\u001b[0m:\u001b[36m185\u001b[0m - \u001b[34m\u001b[1mProcessing post with parsers: ['hashtags']\u001b[0m\n",
      "\u001b[32m2024-06-04 12:19:47.870\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.multi_chain_parser\u001b[0m:\u001b[36mprocess_ref_post\u001b[0m:\u001b[36m187\u001b[0m - \u001b[34m\u001b[1mInstantiating prompts...\u001b[0m\n",
      "\u001b[32m2024-06-04 12:19:47.877\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.multi_chain_parser\u001b[0m:\u001b[36mprocess_ref_post\u001b[0m:\u001b[36m192\u001b[0m - \u001b[34m\u001b[1mInvoking parallel chain...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = multi_chain_parser.process_ref_post(post=post,active_list=[\"hashtags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TwitterEval' object has no attribute 'nested_quotes_citoid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m Eval \u001b[39m=\u001b[39m TwitterEval(config\u001b[39m=\u001b[39mconfig)\n\u001b[1;32m      2\u001b[0m urls \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39mreference_urls\n\u001b[0;32m----> 3\u001b[0m quotes \u001b[39m=\u001b[39m Eval\u001b[39m.\u001b[39;49mnested_quotes_citoid\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(quotes)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TwitterEval' object has no attribute 'nested_quotes_citoid'"
     ]
    }
   ],
   "source": [
    "Eval = TwitterEval(config=config)\n",
    "urls = results.reference_urls\n",
    "quotes = Eval.nested_quotes_citoid\n",
    "print(quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CombinedParserOutput(research_keyword='not-detected', filter_classification=<SciFilterClassfication.NOT_RESEARCH: 'not_research'>, item_types=['webpage', 'forumPost', 'webpage'], reference_urls=['https://paragraph.xyz/@sense-nets/2-project-plan', 'https://twitter.com/i/status/1732044124508008571', 'https://paragraph.xyz/@sense-nets/sense-nets-intro'], reference_tagger=None, multi_reference_tagger=None, keywords=[], topics=[], hashtags=[], metadata_list=[RefMetadata(citoid_url='https://paragraph.xyz/@sense-nets/2-project-plan', url='https://paragraph.xyz/@sense-nets/2-project-plan', item_type='webpage', title='Part 2: Sensemaking Networks Project Plan', summary='Integrating fragmented science social media and reducing the barriers to semantic publishing', image='', debug={'error': None}), RefMetadata(citoid_url='https://twitter.com/i/status/1732044124508008571', url='https://twitter.com/i/status/1732044124508008571', item_type='forumPost', title='Twitter post', summary='', image='', debug={'error': None}), RefMetadata(citoid_url='https://paragraph.xyz/@sense-nets/sense-nets-intro', url='https://paragraph.xyz/@sense-nets/sense-nets-intro', item_type='webpage', title='Sensemaking Networks: Project Introduction', summary='Incorporating science social media into the scientific process', image='', debug={'error': None})], debug={'hashtags': {'prompt': \"New year, new ways to do science! üçæüî≠ I'm excited to share some details about Sensemaking Networks, the project I‚Äôll be developing this year @AsteraInstitute! üßµ1/\\nBlog post version (2 parts): \\nhttps://paragraph.xyz/@sense-nets/sense-nets-intro\\nhttps://paragraph.xyz/@sense-nets/2-project-plan\", 'reasoning': None}})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_quotes1(urls:list):\n",
    "        quotes = []\n",
    "        pattern = re.compile(r'^https://twitter\\.com/.+/[0-9]+$')\n",
    "        for url in urls:\n",
    "            if pattern.match(url):\n",
    "                quotes.append(url)\n",
    "        return quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = check_quotes1(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://twitter.com/i/status/1732044124508008571']\n"
     ]
    }
   ],
   "source": [
    "print(quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-05-21 09:24:12.720\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 1\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.724\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://en.wikipedia.org/wiki/Epic_of_evolution\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.731\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 1\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.731\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://wiki.p2pfoundation.net/Category:Peerproduction#With_the_advent_of_the_P2P_Mode_of_Production%2C_the_community_and_its_common_is_now_the_appropriate_scale\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.732\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 1\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.733\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://integralpermaculture.wordpress.com/peter-pogany/\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.733\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 1\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.734\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://wiki.p2pfoundation.net/Category:Thermodynamic_Efficiencies\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.734\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 1\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.735\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://www.researchgate.net/publication/319248800_Chreods_homeorhesis_and_biofields_Finding_the_right_path_for_science_through_Daoism\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.735\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 1\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.741\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://wiki.p2pfoundation.net/Andre_Gunder_Frank_on_the_History_of_Going_Beyond_Eurocentrism_in_World_Historical_Approaches\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.742\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 1\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.744\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://www.hsgac.senate.gov/wp-content/uploads/Testimony-Vallor-2023-11-08.pdf\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.744\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 1\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.746\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://www.journaloffreespeechlaw.org/\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.746\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 1\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.747\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://lifehacker.com/tech/ai-is-running-out-of-internet\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.747\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 1\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.747\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://civilizationemerging.com/\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.748\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 1\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.749\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://autocatallaxy.com/\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.750\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 1\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.751\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://wiki.p2pfoundation.net/Alexander_Dugin_on_Contemporality\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.751\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 1\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.752\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://wiki.p2pfoundation.net/Andrew_Targowski's_Classification_of_the_Civilizational_Approaches_To_Human_History\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.752\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 1\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.753\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://wiki.p2pfoundation.net/Co-Creative_Labor,_Productive_Democracy_and_the_Partner_State\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.754\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 1\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.754\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m104\u001b[0m - \u001b[34m\u001b[1mskipping citoid for https://t.co/56d7e926y1\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.754\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 1\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.755\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://wiki.p2pfoundation.net/Category:P2P_State_Approaches#What_Lies_Beyond_the_Nation-State\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.755\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 1\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.756\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://wiki.p2pfoundation.net/Alfred_W._McCoy_on_the_Difference_Between_Empires_and_World_Orders\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.756\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 1\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.756\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://wiki.p2pfoundation.net/Category:Peerproperty#Short_Citations\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.756\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 1\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.757\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://www.youtube.com/watch?feature=youtu.be&si=2ByJe6iPjANpy5Mx&v=xbf4BGIBENk\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.758\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 1\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:12.758\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://pedestrianobservations.com/2022/12/30/the-four-quadrants-of-cities-for-transit-revival/\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:13.957\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 2\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:13.958\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://www.researchgate.net/publication/319248800_Chreods_homeorhesis_and_biofields_Finding_the_right_path_for_science_through_Daoism\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:15.885\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 2\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:15.885\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://www.hsgac.senate.gov/wp-content/uploads/Testimony-Vallor-2023-11-08.pdf\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:17.067\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 3\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:17.068\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://www.researchgate.net/publication/319248800_Chreods_homeorhesis_and_biofields_Finding_the_right_path_for_science_through_Daoism\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:17.908\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 3\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:17.909\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://www.hsgac.senate.gov/wp-content/uploads/Testimony-Vallor-2023-11-08.pdf\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:21.180\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 4\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:21.181\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://www.researchgate.net/publication/319248800_Chreods_homeorhesis_and_biofields_Finding_the_right_path_for_science_through_Daoism\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:21.936\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 4\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:21.938\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://www.hsgac.senate.gov/wp-content/uploads/Testimony-Vallor-2023-11-08.pdf\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:29.306\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 5\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:29.309\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://www.researchgate.net/publication/319248800_Chreods_homeorhesis_and_biofields_Finding_the_right_path_for_science_through_Daoism\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:29.404\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mreturn_default_value\u001b[0m:\u001b[36m88\u001b[0m - \u001b[31m\u001b[1mMax retries exceeded. Returning default value.\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:29.965\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mbefore_retry\u001b[0m:\u001b[36m84\u001b[0m - \u001b[33m\u001b[1mRetry attempt 5\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:29.966\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async_retry\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://www.hsgac.senate.gov/wp-content/uploads/Testimony-Vallor-2023-11-08.pdf\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:29.991\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mreturn_default_value\u001b[0m:\u001b[36m88\u001b[0m - \u001b[31m\u001b[1mMax retries exceeded. Returning default value.\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:29.998\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.multi_chain_parser\u001b[0m:\u001b[36mbatch_process_ref_posts\u001b[0m:\u001b[36m232\u001b[0m - \u001b[34m\u001b[1mProcessing 20 posts with parsers: ['keywords', 'topics']\u001b[0m\n",
      "\u001b[32m2024-05-21 09:24:29.999\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.multi_chain_parser\u001b[0m:\u001b[36mbatch_process_ref_posts\u001b[0m:\u001b[36m234\u001b[0m - \u001b[34m\u001b[1mInstantiating prompts...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2387c97ba049a583b933bfd4321a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-05-21 09:24:30.013\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.multi_chain_parser\u001b[0m:\u001b[36mbatch_process_ref_posts\u001b[0m:\u001b[36m248\u001b[0m - \u001b[34m\u001b[1mInvoking parallel chain...\u001b[0m\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/typing.py:373: RuntimeWarning: coroutine 'Runnable.abatch.<locals>.ainvoke' was never awaited\n",
      "  ev_args = tuple(_eval_type(a, globalns, localns, recursive_guard) for a in t.__args__)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# batch process\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results \u001b[39m=\u001b[39m multi_chain_parser\u001b[39m.\u001b[39;49mbatch_process_ref_posts(inputs\u001b[39m=\u001b[39;49minputs[:\u001b[39m20\u001b[39;49m],active_list\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mkeywords\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtopics\u001b[39;49m\u001b[39m\"\u001b[39;49m],batch_size\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/sensemakers/nlp/notebooks/../desci_sense/shared_functions/parsers/multi_chain_parser.py:250\u001b[0m, in \u001b[0;36mMultiChainParser.batch_process_ref_posts\u001b[0;34m(self, inputs, batch_size, active_list)\u001b[0m\n\u001b[1;32m    246\u001b[0m parallel_chain \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_parallel_chain(active_list)\n\u001b[1;32m    248\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mInvoking parallel chain...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 250\u001b[0m results \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m    251\u001b[0m     parallel_chain\u001b[39m.\u001b[39;49mabatch(\n\u001b[1;32m    252\u001b[0m         inst_prompts,\n\u001b[1;32m    253\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    254\u001b[0m     )\n\u001b[1;32m    255\u001b[0m )\n\u001b[1;32m    256\u001b[0m cb\u001b[39m.\u001b[39mprogress_bar\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    258\u001b[0m \u001b[39m# post processing results\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/nest_asyncio.py:35\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     33\u001b[0m task \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mensure_future(main)\n\u001b[1;32m     34\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 35\u001b[0m     \u001b[39mreturn\u001b[39;00m loop\u001b[39m.\u001b[39;49mrun_until_complete(task)\n\u001b[1;32m     36\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m task\u001b[39m.\u001b[39mdone():\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/nest_asyncio.py:84\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     82\u001b[0m     f\u001b[39m.\u001b[39m_log_destroy_pending \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m f\u001b[39m.\u001b[39mdone():\n\u001b[0;32m---> 84\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_once()\n\u001b[1;32m     85\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stopping:\n\u001b[1;32m     86\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/nest_asyncio.py:107\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m     heappop(scheduled)\n\u001b[1;32m    102\u001b[0m timeout \u001b[39m=\u001b[39m (\n\u001b[1;32m    103\u001b[0m     \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m ready \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stopping\n\u001b[1;32m    104\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mmin\u001b[39m(\u001b[39mmax\u001b[39m(\n\u001b[1;32m    105\u001b[0m         scheduled[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_when \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime(), \u001b[39m0\u001b[39m), \u001b[39m86400\u001b[39m) \u001b[39mif\u001b[39;00m scheduled\n\u001b[1;32m    106\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 107\u001b[0m event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_events(event_list)\n\u001b[1;32m    110\u001b[0m end_time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime() \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clock_resolution\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/selectors.py:561\u001b[0m, in \u001b[0;36mKqueueSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    559\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    560\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 561\u001b[0m     kev_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_selector\u001b[39m.\u001b[39mcontrol(\u001b[39mNone\u001b[39;00m, max_ev, timeout)\n\u001b[1;32m    562\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    563\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# batch process\n",
    "results = multi_chain_parser.batch_process_ref_posts(inputs=inputs[:20],active_list=[\"keywords\", \"topics\"],batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Reasoning Steps]\n",
      "\n",
      "**\n",
      "\n",
      "* Analyzed the post's content to identify key concepts and issues.\n",
      "* Considered both general and specific keywords relevant to the topics discussed.\n",
      "* Included a special keyword to indicate if the post is related to academic research.\n",
      "\n",
      "\n",
      "**\n",
      "\n",
      "[Candidate Keywords]\n",
      "\n",
      "**\n",
      "\n",
      "* #sustainability\n",
      "* #naturalcapital\n",
      "* #resourcemanagement\n",
      "* #socialcapital\n",
      "* #regenerativeculture\n",
      "* #conservation\n",
      "* #consumption\n",
      "\n",
      "\n",
      "**\n"
     ]
    }
   ],
   "source": [
    "print(results[1].debug['keywords']['reasoning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in results:\n",
    "    try:\n",
    "        p.debug['topics']['full_text']\n",
    "    except:\n",
    "        print(p.debug['topics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update predictions to dataframe\n",
    "df['Predicted Label'] = [x.filter_classification.value for x in results]\n",
    "df['Reasoning Steps'] = [\"Keywords: \"+str(x.debug['topics']['reasoning'])+\"Topics: \"+str(x.debug['keywords']['reasoning']) for x in results]\n",
    "df['Keywords'] = [x.keywords for x in results]\n",
    "df['Topics'] = [x.topics for x in results]\n",
    "df['Ref item types'] = [x.item_types for x in results]\n",
    "df['academic_keyword'] = [x.research_keyword for x in results]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'batch_size': 5, 'wandb_config': {'entity': 'common-sense-makers', 'project': 'st-demo-sandbox'}, 'parser_configs': {'0': {'name': 'refs_tagger', 'type': '<ParserChainType.REFERENCE_TAGGER:', 'llm_config': {'llm_type': 'random_parser'}, 'temperature': 0.5, 'use_metadata': True, 'is_ref': True}, '1': {'name': 'multi_refs_tagger', 'type': '<ParserChainType.MULTI_REF_TAGGER:', 'llm_config': {'llm_type': 'mistralai/mixtral-8x7b-instruct:nitro'}, 'temperature': 0.6, 'use_metadata': True, 'is_multi_ref': True}, '2': {'name': 'topics', 'type': '<ParserChainType.TOPICS:', 'llm_config': {'llm_type': 'mistralai/mixtral-8x7b-instruct:nitro'}, 'temperature': 0.6, 'use_metadata': True, 'is_topic': True}, '3': {'name': 'keywords', 'type': '<ParserChainType.KEYWORDS:', 'llm_config': {'llm_type': 'mistralai/mixtral-8x7b-instruct:nitro'}, 'temperature': 0.6, 'use_metadata': True, 'max_keywords': 6}, '4': {'name': 'hashtags', 'type': '<ParserChainType.HASHTAGS:', 'llm_config': {'llm_type': 'mistralai/mistral-7b-instruct'}, 'temperature': 0.6, 'use_metadata': False, 'max_hashtags': 20}}, 'post_process_type': 'PostProcessType.COMBINED', 'openrouter_api_config': {'openrouter_api_base': 'https://openrouter.ai/api/v1', 'openrouter_api_key': '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', 'openrouter_referer': 'http://localhost:3000'}, 'metadata_extract_config': {'extraction_method': '<MetadataExtractionType.CITOID:', 'max_summary_length': 500}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:yrayhhuy) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883778383d114693903eb0708fbfc57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vibrant-armadillo-241</strong> at: <a href='https://wandb.ai/common-sense-makers/testing/runs/yrayhhuy' target=\"_blank\">https://wandb.ai/common-sense-makers/testing/runs/yrayhhuy</a><br/> View project at: <a href='https://wandb.ai/common-sense-makers/testing' target=\"_blank\">https://wandb.ai/common-sense-makers/testing</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240520_131353-yrayhhuy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:yrayhhuy). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf095d2d2365439cb92d859e60157cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011114801388854782, max=1.0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/shaharorielkagan/sensemakers/nlp/notebooks/wandb/run-20240520_143240-n9xtga0v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/common-sense-makers/filter_evaluation/runs/n9xtga0v' target=\"_blank\">amber-plant-54</a></strong> to <a href='https://wandb.ai/common-sense-makers/filter_evaluation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/common-sense-makers/filter_evaluation' target=\"_blank\">https://wandb.ai/common-sense-makers/filter_evaluation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/common-sense-makers/filter_evaluation/runs/n9xtga0v' target=\"_blank\">https://wandb.ai/common-sense-makers/filter_evaluation/runs/n9xtga0v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9688313feba8451aa7dc35decd2349af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.274 MB of 0.274 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">amber-plant-54</strong> at: <a href='https://wandb.ai/common-sense-makers/filter_evaluation/runs/n9xtga0v' target=\"_blank\">https://wandb.ai/common-sense-makers/filter_evaluation/runs/n9xtga0v</a><br/> View project at: <a href='https://wandb.ai/common-sense-makers/filter_evaluation' target=\"_blank\">https://wandb.ai/common-sense-makers/filter_evaluation</a><br/>Synced 4 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240520_143240-n9xtga0v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Log dataframe in wandb\n",
    "wandb.login()\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "#TODO move from testing\n",
    "run = wandb.init(project=\"filter_evaluation\", job_type=\"predictions\")\n",
    "\n",
    "# Create the evaluation artifact\n",
    "current_datetime = datetime.now()\n",
    "time = current_datetime.strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "\n",
    "artifact = wandb.Artifact(\"prediction_evaluation-\" + str(time), type=\"evaluation\")\n",
    "\n",
    "# Create a wandb.Table from the Pandas DataFrame\n",
    "table = wandb.Table(dataframe=df)\n",
    "\n",
    "# Add the wandb.Table to the artifact\n",
    "artifact.add(table, \"prediction_evaluation\")\n",
    "\n",
    "# model_info is your model metadata\n",
    "run.config.update(config)\n",
    "\n",
    " # Log the artifact\n",
    "wandb.log_artifact(artifact, aliases=[\"latest\"])\n",
    "\n",
    "wandb.run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_posts = []\n",
    "for i in range(20,len(df[\"Text\"])):\n",
    "    print(i)\n",
    "    p = df['Text'][i]\n",
    "    r = convert_text_to_ref_post(p)\n",
    "    try:\n",
    "        result=multi_chain_parser.process_ref_post(r,active_list=[\"topics\",'keywords'])\n",
    "    except Exception as e:\n",
    "        print(\"Post with text: \",p)\n",
    "        print('and url: ',df['postURL'][i])\n",
    "        print(\"has raised an exception: \",e) \n",
    "        bad_posts.append((df['postURL'][i],e))\n",
    "          \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(28593) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(28594) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(28595) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(28596) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(28597) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(28598) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(28599) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(28600) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(28601) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(28602) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(28603) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(28604) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "print(bad_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_config_construct(config):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"John Doe\",\n",
      "    \"age\": 30,\n",
      "    \"address\": {\n",
      "        \"street\": \"123 Main St\",\n",
      "        \"city\": \"Springfield\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import inspect\n",
    "\n",
    "def obj_to_dict(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: obj_to_dict(v) for k, v in obj.items()}\n",
    "    elif hasattr(obj, \"__dict__\"):\n",
    "        return {k: obj_to_dict(v) for k, v in obj.__dict__.items() if not k.startswith('_')}\n",
    "    elif isinstance(obj, list):\n",
    "        return [obj_to_dict(i) for i in obj]\n",
    "    elif isinstance(obj, tuple):\n",
    "        return tuple(obj_to_dict(i) for i in obj)\n",
    "    elif isinstance(obj, set):\n",
    "        return {obj_to_dict(i) for i in obj}\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "def obj_to_json(obj):\n",
    "    return json.dumps(obj_to_dict(obj), indent=4)\n",
    "\n",
    "# Example classes\n",
    "class Address:\n",
    "    def __init__(self, street, city):\n",
    "        self.street = street\n",
    "        self.city = city\n",
    "\n",
    "class Person:\n",
    "    def __init__(self, name, age, address):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "        self.address = address\n",
    "\n",
    "# Example usage\n",
    "address = Address(\"123 Main St\", \"Springfield\")\n",
    "person = Person(\"John Doe\", 30, address)\n",
    "\n",
    "print(obj_to_json(person))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'openrouter_api_config': {'openrouter_api_base': 'https://openrouter.ai/api/v1', 'openrouter_api_key': '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', 'openrouter_referer': 'http://localhost:3000'}, 'parser_configs': [{'name': 'multi_refs_tagger', 'type': {}, 'llm_config': {'llm_type': 'openai/gpt-3.5-turbo-0125', 'temperature': '0.6'}, 'use_metadata': True, 'is_multi_ref': True}, {'name': 'topics', 'type': {}, 'llm_config': {'llm_type': 'openai/gpt-3.5-turbo-0125', 'temperature': '0.6'}, 'use_metadata': True, 'is_topic': True}, {'name': 'keywords', 'type': {}, 'llm_config': {'llm_type': 'openai/gpt-3.5-turbo-0125', 'temperature': '0.6'}, 'use_metadata': True, 'max_keywords': 6}, {'name': 'hashtags', 'type': {}, 'llm_config': {'llm_type': 'mistralai/mistral-7b-instruct', 'temperature': '0.6'}, 'use_metadata': False, 'max_hashtags': 20}], 'metadata_extract_config': {'extraction_method': {}, 'max_summary_length': 500}, 'wandb_config': {'entity': 'common-sense-makers', 'project': 'st-demo-sandbox'}, 'batch_size': 5, 'post_process_type': {}}\n"
     ]
    }
   ],
   "source": [
    "print(obj_to_dict(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import wandb\n",
    "\n",
    "def parse_string_to_dict(s):\n",
    "    \"\"\"Parses a string representation of a dictionary or object.\"\"\"\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Custom parsing logic for object-like strings\n",
    "    result = {}\n",
    "    # Split by spaces, but keep quoted strings together\n",
    "    parts = re.findall(r'(\\w+)=\\'(.*?)\\'|(\\w+)=([^\\s]+)', s)\n",
    "    \n",
    "    for part in parts:\n",
    "        if part[0]:\n",
    "            key, value = part[0], part[1]\n",
    "        else:\n",
    "            key, value = part[2], part[3]\n",
    "        \n",
    "        # Attempt to parse the value further\n",
    "        try:\n",
    "            value = ast.literal_eval(value)\n",
    "        except Exception:\n",
    "            if isinstance(value, str) and '=' in value:\n",
    "                value = parse_string_to_dict(value)\n",
    "        \n",
    "        result[key] = value\n",
    "    \n",
    "    return result if result else s\n",
    "\n",
    "def obj_to_dict(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: obj_to_dict(v) for k, v in obj.items()}\n",
    "    elif hasattr(obj, \"__dict__\"):\n",
    "        return {k: obj_to_dict(v) for k, v in obj.__dict__.items() if not k.startswith('_')}\n",
    "    elif isinstance(obj, list):\n",
    "        return [obj_to_dict(i) for i in obj]\n",
    "    elif isinstance(obj, tuple):\n",
    "        return tuple(obj_to_dict(i) for i in obj)\n",
    "    elif isinstance(obj, set):\n",
    "        return {obj_to_dict(i) for i in obj}\n",
    "    elif isinstance(obj, str):\n",
    "        return parse_string_to_dict(obj)\n",
    "    else:\n",
    "        return obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config:  {}\n",
      "+++++\n",
      "transformed_config:  {}\n",
      "++++++++\n",
      "'parser_configs'\n",
      "config:  {}\n",
      "+++++\n",
      "transformed_config:  {}\n",
      "++++++++\n",
      "'parser_configs'\n",
      "config:  {}\n",
      "+++++\n",
      "transformed_config:  {}\n",
      "++++++++\n",
      "'parser_configs'\n",
      "config:  {}\n",
      "+++++\n",
      "transformed_config:  {}\n",
      "++++++++\n",
      "'parser_configs'\n",
      "config:  {'batch_size': 5, 'wandb_config': \"entity='common-sense-makers' project='st-demo-sandbox'\", 'parser_configs': [\"name='multi_refs_tagger' type=<ParserChainType.MULTI_REF_TAGGER: 'multi_reference_tagger'> llm_config=LLMConfig(llm_type='openai/gpt-3.5-turbo-0125', temperature='0.6') use_metadata=True is_multi_ref=True\", \"name='topics' type=<ParserChainType.TOPICS: 'topics'> llm_config=LLMConfig(llm_type='openai/gpt-3.5-turbo-0125', temperature='0.6') use_metadata=True is_topic=True\", \"name='keywords' type=<ParserChainType.KEYWORDS: 'keywords'> llm_config=LLMConfig(llm_type='openai/gpt-3.5-turbo-0125', temperature='0.6') use_metadata=True max_keywords=6\", \"name='hashtags' type=<ParserChainType.HASHTAGS: 'hashtags'> llm_config=LLMConfig(llm_type='mistralai/mistral-7b-instruct', temperature='0.6') use_metadata=False max_hashtags=20\"], 'post_process_type': 'PostProcessType.COMBINED', 'openrouter_api_config': \"openrouter_api_base='https://openrouter.ai/api/v1' openrouter_api_key='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' openrouter_referer='http://localhost:3000'\", 'metadata_extract_config': \"extraction_method=<MetadataExtractionType.CITOID: 'citoid'> max_summary_length=500\"}\n",
      "+++++\n",
      "transformed_config:  {'batch_size': 5, 'wandb_config': {'entity': 'common-sense-makers', 'project': 'st-demo-sandbox'}, 'parser_configs': [{'name': 'multi_refs_tagger', 'type': '<ParserChainType.MULTI_REF_TAGGER:', 'llm_config': {'llm_type': 'openai/gpt-3.5-turbo-0125'}, 'temperature': 0.6, 'use_metadata': True, 'is_multi_ref': True}, {'name': 'topics', 'type': '<ParserChainType.TOPICS:', 'llm_config': {'llm_type': 'openai/gpt-3.5-turbo-0125'}, 'temperature': 0.6, 'use_metadata': True, 'is_topic': True}, {'name': 'keywords', 'type': '<ParserChainType.KEYWORDS:', 'llm_config': {'llm_type': 'openai/gpt-3.5-turbo-0125'}, 'temperature': 0.6, 'use_metadata': True, 'max_keywords': 6}, {'name': 'hashtags', 'type': '<ParserChainType.HASHTAGS:', 'llm_config': {'llm_type': 'mistralai/mistral-7b-instruct'}, 'temperature': 0.6, 'use_metadata': False, 'max_hashtags': 20}], 'post_process_type': 'PostProcessType.COMBINED', 'openrouter_api_config': {'openrouter_api_base': 'https://openrouter.ai/api/v1', 'openrouter_api_key': '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', 'openrouter_referer': 'http://localhost:3000'}, 'metadata_extract_config': {'extraction_method': '<MetadataExtractionType.CITOID:', 'max_summary_length': 500}}\n",
      "++++++++\n",
      "OUT\n",
      "config:  {'batch_size': 5, 'wandb_config': \"entity='common-sense-makers' project='st-demo-sandbox'\", 'parser_configs': [\"name='multi_refs_tagger' type=<ParserChainType.MULTI_REF_TAGGER: 'multi_reference_tagger'> llm_config=LLMConfig(llm_type='openai/gpt-3.5-turbo-0125', temperature='0.6') use_metadata=True is_multi_ref=True\", \"name='topics' type=<ParserChainType.TOPICS: 'topics'> llm_config=LLMConfig(llm_type='openai/gpt-3.5-turbo-0125', temperature='0.6') use_metadata=True is_topic=True\", \"name='keywords' type=<ParserChainType.KEYWORDS: 'keywords'> llm_config=LLMConfig(llm_type='openai/gpt-3.5-turbo-0125', temperature='0.6') use_metadata=True max_keywords=6\", \"name='hashtags' type=<ParserChainType.HASHTAGS: 'hashtags'> llm_config=LLMConfig(llm_type='mistralai/mistral-7b-instruct', temperature='0.6') use_metadata=False max_hashtags=20\"], 'post_process_type': 'PostProcessType.COMBINED', 'openrouter_api_config': \"openrouter_api_base='https://openrouter.ai/api/v1' openrouter_api_key='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' openrouter_referer='http://localhost:3000'\", 'metadata_extract_config': \"extraction_method=<MetadataExtractionType.CITOID: 'citoid'> max_summary_length=500\"}\n",
      "+++++\n",
      "transformed_config:  {'batch_size': 5, 'wandb_config': {'entity': 'common-sense-makers', 'project': 'st-demo-sandbox'}, 'parser_configs': [{'name': 'multi_refs_tagger', 'type': '<ParserChainType.MULTI_REF_TAGGER:', 'llm_config': {'llm_type': 'openai/gpt-3.5-turbo-0125'}, 'temperature': 0.6, 'use_metadata': True, 'is_multi_ref': True}, {'name': 'topics', 'type': '<ParserChainType.TOPICS:', 'llm_config': {'llm_type': 'openai/gpt-3.5-turbo-0125'}, 'temperature': 0.6, 'use_metadata': True, 'is_topic': True}, {'name': 'keywords', 'type': '<ParserChainType.KEYWORDS:', 'llm_config': {'llm_type': 'openai/gpt-3.5-turbo-0125'}, 'temperature': 0.6, 'use_metadata': True, 'max_keywords': 6}, {'name': 'hashtags', 'type': '<ParserChainType.HASHTAGS:', 'llm_config': {'llm_type': 'mistralai/mistral-7b-instruct'}, 'temperature': 0.6, 'use_metadata': False, 'max_hashtags': 20}], 'post_process_type': 'PostProcessType.COMBINED', 'openrouter_api_config': {'openrouter_api_base': 'https://openrouter.ai/api/v1', 'openrouter_api_key': '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', 'openrouter_referer': 'http://localhost:3000'}, 'metadata_extract_config': {'extraction_method': '<MetadataExtractionType.CITOID:', 'max_summary_length': 500}}\n",
      "++++++++\n",
      "OUT\n",
      "config:  {'batch_size': 5, 'wandb_config': \"entity='common-sense-makers' project='st-demo-sandbox'\", 'parser_configs': [\"name='refs_tagger' type=<ParserChainType.REFERENCE_TAGGER: 'reference_tagger'> llm_config=LLMConfig(llm_type='google/gemma-7b-it:nitro', temperature='0.6') use_metadata=True is_ref=True\", \"name='multi_refs_tagger' type=<ParserChainType.MULTI_REF_TAGGER: 'multi_reference_tagger'> llm_config=LLMConfig(llm_type='google/gemma-7b-it:nitro', temperature='0.6') use_metadata=True is_multi_ref=True\", \"name='topics' type=<ParserChainType.TOPICS: 'topics'> llm_config=LLMConfig(llm_type='google/gemma-7b-it:nitro', temperature='0.6') use_metadata=True is_topic=True\", \"name='keywords' type=<ParserChainType.KEYWORDS: 'keywords'> llm_config=LLMConfig(llm_type='google/gemma-7b-it:nitro', temperature='0.6') use_metadata=True max_keywords=6\", \"name='hashtags' type=<ParserChainType.HASHTAGS: 'hashtags'> llm_config=LLMConfig(llm_type='mistralai/mistral-7b-instruct', temperature='0.6') use_metadata=False max_hashtags=20\"], 'post_process_type': 'PostProcessType.COMBINED', 'openrouter_api_config': \"openrouter_api_base='https://openrouter.ai/api/v1' openrouter_api_key='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' openrouter_referer='http://localhost:3000'\", 'metadata_extract_config': \"extraction_method=<MetadataExtractionType.CITOID: 'citoid'> max_summary_length=500\"}\n",
      "+++++\n",
      "transformed_config:  {'batch_size': 5, 'wandb_config': {'entity': 'common-sense-makers', 'project': 'st-demo-sandbox'}, 'parser_configs': [{'name': 'refs_tagger', 'type': '<ParserChainType.REFERENCE_TAGGER:', 'llm_config': {'llm_type': 'google/gemma-7b-it:nitro'}, 'temperature': 0.6, 'use_metadata': True, 'is_ref': True}, {'name': 'multi_refs_tagger', 'type': '<ParserChainType.MULTI_REF_TAGGER:', 'llm_config': {'llm_type': 'google/gemma-7b-it:nitro'}, 'temperature': 0.6, 'use_metadata': True, 'is_multi_ref': True}, {'name': 'topics', 'type': '<ParserChainType.TOPICS:', 'llm_config': {'llm_type': 'google/gemma-7b-it:nitro'}, 'temperature': 0.6, 'use_metadata': True, 'is_topic': True}, {'name': 'keywords', 'type': '<ParserChainType.KEYWORDS:', 'llm_config': {'llm_type': 'google/gemma-7b-it:nitro'}, 'temperature': 0.6, 'use_metadata': True, 'max_keywords': 6}, {'name': 'hashtags', 'type': '<ParserChainType.HASHTAGS:', 'llm_config': {'llm_type': 'mistralai/mistral-7b-instruct'}, 'temperature': 0.6, 'use_metadata': False, 'max_hashtags': 20}], 'post_process_type': 'PostProcessType.COMBINED', 'openrouter_api_config': {'openrouter_api_base': 'https://openrouter.ai/api/v1', 'openrouter_api_key': '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', 'openrouter_referer': 'http://localhost:3000'}, 'metadata_extract_config': {'extraction_method': '<MetadataExtractionType.CITOID:', 'max_summary_length': 500}}\n",
      "++++++++\n",
      "OUT\n",
      "config:  {'batch_size': 5, 'wandb_config': \"entity='common-sense-makers' project='st-demo-sandbox'\", 'parser_configs': [\"name='refs_tagger' type=<ParserChainType.REFERENCE_TAGGER: 'reference_tagger'> llm_config=LLMConfig(llm_type='google/gemma-7b-it:nitro', temperature='0.6') use_metadata=True is_ref=True\", \"name='multi_refs_tagger' type=<ParserChainType.MULTI_REF_TAGGER: 'multi_reference_tagger'> llm_config=LLMConfig(llm_type='google/gemma-7b-it:nitro', temperature='0.6') use_metadata=True is_multi_ref=True\", \"name='topics' type=<ParserChainType.TOPICS: 'topics'> llm_config=LLMConfig(llm_type='google/gemma-7b-it:nitro', temperature='0.6') use_metadata=True is_topic=True\", \"name='keywords' type=<ParserChainType.KEYWORDS: 'keywords'> llm_config=LLMConfig(llm_type='google/gemma-7b-it:nitro', temperature='0.6') use_metadata=True max_keywords=6\", \"name='hashtags' type=<ParserChainType.HASHTAGS: 'hashtags'> llm_config=LLMConfig(llm_type='mistralai/mistral-7b-instruct', temperature='0.6') use_metadata=False max_hashtags=20\"], 'post_process_type': 'PostProcessType.COMBINED', 'openrouter_api_config': \"openrouter_api_base='https://openrouter.ai/api/v1' openrouter_api_key='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' openrouter_referer='http://localhost:3000'\", 'metadata_extract_config': \"extraction_method=<MetadataExtractionType.CITOID: 'citoid'> max_summary_length=500\"}\n",
      "+++++\n",
      "transformed_config:  {'batch_size': 5, 'wandb_config': {'entity': 'common-sense-makers', 'project': 'st-demo-sandbox'}, 'parser_configs': [{'name': 'refs_tagger', 'type': '<ParserChainType.REFERENCE_TAGGER:', 'llm_config': {'llm_type': 'google/gemma-7b-it:nitro'}, 'temperature': 0.6, 'use_metadata': True, 'is_ref': True}, {'name': 'multi_refs_tagger', 'type': '<ParserChainType.MULTI_REF_TAGGER:', 'llm_config': {'llm_type': 'google/gemma-7b-it:nitro'}, 'temperature': 0.6, 'use_metadata': True, 'is_multi_ref': True}, {'name': 'topics', 'type': '<ParserChainType.TOPICS:', 'llm_config': {'llm_type': 'google/gemma-7b-it:nitro'}, 'temperature': 0.6, 'use_metadata': True, 'is_topic': True}, {'name': 'keywords', 'type': '<ParserChainType.KEYWORDS:', 'llm_config': {'llm_type': 'google/gemma-7b-it:nitro'}, 'temperature': 0.6, 'use_metadata': True, 'max_keywords': 6}, {'name': 'hashtags', 'type': '<ParserChainType.HASHTAGS:', 'llm_config': {'llm_type': 'mistralai/mistral-7b-instruct'}, 'temperature': 0.6, 'use_metadata': False, 'max_hashtags': 20}], 'post_process_type': 'PostProcessType.COMBINED', 'openrouter_api_config': {'openrouter_api_base': 'https://openrouter.ai/api/v1', 'openrouter_api_key': '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', 'openrouter_referer': 'http://localhost:3000'}, 'metadata_extract_config': {'extraction_method': '<MetadataExtractionType.CITOID:', 'max_summary_length': 500}}\n",
      "++++++++\n",
      "OUT\n",
      "config:  {'batch_size': 5, 'wandb_config': \"entity='common-sense-makers' project='st-demo-sandbox'\", 'parser_configs': [\"name='refs_tagger' type=<ParserChainType.REFERENCE_TAGGER: 'reference_tagger'> llm_config=LLMConfig(llm_type='google/gemma-7b-it', temperature='0.6') use_metadata=True is_ref=True\", \"name='multi_refs_tagger' type=<ParserChainType.MULTI_REF_TAGGER: 'multi_reference_tagger'> llm_config=LLMConfig(llm_type='google/gemma-7b-it', temperature='0.6') use_metadata=True is_multi_ref=True\", \"name='topics' type=<ParserChainType.TOPICS: 'topics'> llm_config=LLMConfig(llm_type='google/gemma-7b-it', temperature='0.6') use_metadata=True is_topic=True\", \"name='keywords' type=<ParserChainType.KEYWORDS: 'keywords'> llm_config=LLMConfig(llm_type='google/gemma-7b-it', temperature='0.6') use_metadata=True max_keywords=6\", \"name='hashtags' type=<ParserChainType.HASHTAGS: 'hashtags'> llm_config=LLMConfig(llm_type='mistralai/mistral-7b-instruct', temperature='0.6') use_metadata=False max_hashtags=20\"], 'post_process_type': 'PostProcessType.COMBINED', 'openrouter_api_config': \"openrouter_api_base='https://openrouter.ai/api/v1' openrouter_api_key='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' openrouter_referer='http://localhost:3000'\", 'metadata_extract_config': \"extraction_method=<MetadataExtractionType.CITOID: 'citoid'> max_summary_length=500\"}\n",
      "+++++\n",
      "transformed_config:  {'batch_size': 5, 'wandb_config': {'entity': 'common-sense-makers', 'project': 'st-demo-sandbox'}, 'parser_configs': [{'name': 'refs_tagger', 'type': '<ParserChainType.REFERENCE_TAGGER:', 'llm_config': {'llm_type': 'google/gemma-7b-it'}, 'temperature': 0.6, 'use_metadata': True, 'is_ref': True}, {'name': 'multi_refs_tagger', 'type': '<ParserChainType.MULTI_REF_TAGGER:', 'llm_config': {'llm_type': 'google/gemma-7b-it'}, 'temperature': 0.6, 'use_metadata': True, 'is_multi_ref': True}, {'name': 'topics', 'type': '<ParserChainType.TOPICS:', 'llm_config': {'llm_type': 'google/gemma-7b-it'}, 'temperature': 0.6, 'use_metadata': True, 'is_topic': True}, {'name': 'keywords', 'type': '<ParserChainType.KEYWORDS:', 'llm_config': {'llm_type': 'google/gemma-7b-it'}, 'temperature': 0.6, 'use_metadata': True, 'max_keywords': 6}, {'name': 'hashtags', 'type': '<ParserChainType.HASHTAGS:', 'llm_config': {'llm_type': 'mistralai/mistral-7b-instruct'}, 'temperature': 0.6, 'use_metadata': False, 'max_hashtags': 20}], 'post_process_type': 'PostProcessType.COMBINED', 'openrouter_api_config': {'openrouter_api_base': 'https://openrouter.ai/api/v1', 'openrouter_api_key': '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', 'openrouter_referer': 'http://localhost:3000'}, 'metadata_extract_config': {'extraction_method': '<MetadataExtractionType.CITOID:', 'max_summary_length': 500}}\n",
      "++++++++\n",
      "OUT\n",
      "config:  {}\n",
      "+++++\n",
      "transformed_config:  {}\n",
      "++++++++\n",
      "'parser_configs'\n",
      "config:  {}\n",
      "+++++\n",
      "transformed_config:  {}\n",
      "++++++++\n",
      "'parser_configs'\n",
      "config:  {}\n",
      "+++++\n",
      "transformed_config:  {}\n",
      "++++++++\n",
      "'parser_configs'\n",
      "config:  {}\n",
      "+++++\n",
      "transformed_config:  {}\n",
      "++++++++\n",
      "'parser_configs'\n",
      "config:  {}\n",
      "+++++\n",
      "transformed_config:  {}\n",
      "++++++++\n",
      "'parser_configs'\n",
      "config:  {'batch_size': 5, 'wandb_config': \"entity='common-sense-makers' project='st-demo-sandbox'\", 'parser_configs': [\"name='refs_tagger' type=<ParserChainType.REFERENCE_TAGGER: 'reference_tagger'> llm_config=LLMConfig(llm_type='anthropic/claude-3-haiku', temperature='0.6') use_metadata=True is_ref=True\", \"name='multi_refs_tagger' type=<ParserChainType.MULTI_REF_TAGGER: 'multi_reference_tagger'> llm_config=LLMConfig(llm_type='anthropic/claude-3-haiku', temperature='0.6') use_metadata=True is_multi_ref=True\", \"name='topics' type=<ParserChainType.TOPICS: 'topics'> llm_config=LLMConfig(llm_type='anthropic/claude-3-haiku', temperature='0.6') use_metadata=True is_topic=True\", \"name='keywords' type=<ParserChainType.KEYWORDS: 'keywords'> llm_config=LLMConfig(llm_type='anthropic/claude-3-haiku', temperature='0.6') use_metadata=True max_keywords=6\", \"name='hashtags' type=<ParserChainType.HASHTAGS: 'hashtags'> llm_config=LLMConfig(llm_type='mistralai/mistral-7b-instruct', temperature='0.6') use_metadata=False max_hashtags=20\"], 'post_process_type': 'PostProcessType.COMBINED', 'openrouter_api_config': \"openrouter_api_base='https://openrouter.ai/api/v1' openrouter_api_key='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' openrouter_referer='http://localhost:3000'\", 'metadata_extract_config': \"extraction_method=<MetadataExtractionType.CITOID: 'citoid'> max_summary_length=500\"}\n",
      "+++++\n",
      "transformed_config:  {'batch_size': 5, 'wandb_config': {'entity': 'common-sense-makers', 'project': 'st-demo-sandbox'}, 'parser_configs': [{'name': 'refs_tagger', 'type': '<ParserChainType.REFERENCE_TAGGER:', 'llm_config': {'llm_type': 'anthropic/claude-3-haiku'}, 'temperature': 0.6, 'use_metadata': True, 'is_ref': True}, {'name': 'multi_refs_tagger', 'type': '<ParserChainType.MULTI_REF_TAGGER:', 'llm_config': {'llm_type': 'anthropic/claude-3-haiku'}, 'temperature': 0.6, 'use_metadata': True, 'is_multi_ref': True}, {'name': 'topics', 'type': '<ParserChainType.TOPICS:', 'llm_config': {'llm_type': 'anthropic/claude-3-haiku'}, 'temperature': 0.6, 'use_metadata': True, 'is_topic': True}, {'name': 'keywords', 'type': '<ParserChainType.KEYWORDS:', 'llm_config': {'llm_type': 'anthropic/claude-3-haiku'}, 'temperature': 0.6, 'use_metadata': True, 'max_keywords': 6}, {'name': 'hashtags', 'type': '<ParserChainType.HASHTAGS:', 'llm_config': {'llm_type': 'mistralai/mistral-7b-instruct'}, 'temperature': 0.6, 'use_metadata': False, 'max_hashtags': 20}], 'post_process_type': 'PostProcessType.COMBINED', 'openrouter_api_config': {'openrouter_api_base': 'https://openrouter.ai/api/v1', 'openrouter_api_key': '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', 'openrouter_referer': 'http://localhost:3000'}, 'metadata_extract_config': {'extraction_method': '<MetadataExtractionType.CITOID:', 'max_summary_length': 500}}\n",
      "++++++++\n",
      "OUT\n",
      "config:  {}\n",
      "+++++\n",
      "transformed_config:  {}\n",
      "++++++++\n",
      "'parser_configs'\n",
      "config:  {}\n",
      "+++++\n",
      "transformed_config:  {}\n",
      "++++++++\n",
      "'parser_configs'\n",
      "config:  {'batch_size': 5, 'wandb_config': \"entity='common-sense-makers' project='st-demo-sandbox'\", 'parser_configs': [\"name='refs_tagger' type=<ParserChainType.REFERENCE_TAGGER: 'reference_tagger'> llm_config=LLMConfig(llm_type='google/gemma-7b-it', temperature='0.6') use_metadata=True is_ref=True\", \"name='multi_refs_tagger' type=<ParserChainType.MULTI_REF_TAGGER: 'multi_reference_tagger'> llm_config=LLMConfig(llm_type='google/gemma-7b-it', temperature='0.6') use_metadata=True is_multi_ref=True\", \"name='topics' type=<ParserChainType.TOPICS: 'topics'> llm_config=LLMConfig(llm_type='google/gemma-7b-it', temperature='0.6') use_metadata=True is_topic=True\", \"name='keywords' type=<ParserChainType.KEYWORDS: 'keywords'> llm_config=LLMConfig(llm_type='google/gemma-7b-it', temperature='0.6') use_metadata=True max_keywords=6\", \"name='hashtags' type=<ParserChainType.HASHTAGS: 'hashtags'> llm_config=LLMConfig(llm_type='mistralai/mistral-7b-instruct', temperature='0.6') use_metadata=False max_hashtags=20\"], 'post_process_type': 'PostProcessType.COMBINED', 'openrouter_api_config': \"openrouter_api_base='https://openrouter.ai/api/v1' openrouter_api_key='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' openrouter_referer='http://localhost:3000'\", 'metadata_extract_config': \"extraction_method=<MetadataExtractionType.CITOID: 'citoid'> max_summary_length=500\"}\n",
      "+++++\n",
      "transformed_config:  {'batch_size': 5, 'wandb_config': {'entity': 'common-sense-makers', 'project': 'st-demo-sandbox'}, 'parser_configs': [{'name': 'refs_tagger', 'type': '<ParserChainType.REFERENCE_TAGGER:', 'llm_config': {'llm_type': 'google/gemma-7b-it'}, 'temperature': 0.6, 'use_metadata': True, 'is_ref': True}, {'name': 'multi_refs_tagger', 'type': '<ParserChainType.MULTI_REF_TAGGER:', 'llm_config': {'llm_type': 'google/gemma-7b-it'}, 'temperature': 0.6, 'use_metadata': True, 'is_multi_ref': True}, {'name': 'topics', 'type': '<ParserChainType.TOPICS:', 'llm_config': {'llm_type': 'google/gemma-7b-it'}, 'temperature': 0.6, 'use_metadata': True, 'is_topic': True}, {'name': 'keywords', 'type': '<ParserChainType.KEYWORDS:', 'llm_config': {'llm_type': 'google/gemma-7b-it'}, 'temperature': 0.6, 'use_metadata': True, 'max_keywords': 6}, {'name': 'hashtags', 'type': '<ParserChainType.HASHTAGS:', 'llm_config': {'llm_type': 'mistralai/mistral-7b-instruct'}, 'temperature': 0.6, 'use_metadata': False, 'max_hashtags': 20}], 'post_process_type': 'PostProcessType.COMBINED', 'openrouter_api_config': {'openrouter_api_base': 'https://openrouter.ai/api/v1', 'openrouter_api_key': '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', 'openrouter_referer': 'http://localhost:3000'}, 'metadata_extract_config': {'extraction_method': '<MetadataExtractionType.CITOID:', 'max_summary_length': 500}}\n",
      "++++++++\n",
      "OUT\n",
      "config:  {'batch_size': 5, 'wandb_config': \"entity='common-sense-makers' project='st-demo-sandbox'\", 'parser_configs': [\"name='refs_tagger' type=<ParserChainType.REFERENCE_TAGGER: 'reference_tagger'> llm_config=LLMConfig(llm_type='mistralai/mixtral-8x7b-instruct:nitro', temperature='0.6') use_metadata=True is_ref=True\", \"name='multi_refs_tagger' type=<ParserChainType.MULTI_REF_TAGGER: 'multi_reference_tagger'> llm_config=LLMConfig(llm_type='mistralai/mixtral-8x7b-instruct:nitro', temperature='0.6') use_metadata=True is_multi_ref=True\", \"name='topics' type=<ParserChainType.TOPICS: 'topics'> llm_config=LLMConfig(llm_type='mistralai/mixtral-8x7b-instruct:nitro', temperature='0.6') use_metadata=True is_topic=True\", \"name='keywords' type=<ParserChainType.KEYWORDS: 'keywords'> llm_config=LLMConfig(llm_type='mistralai/mixtral-8x7b-instruct:nitro', temperature='0.6') use_metadata=True max_keywords=6\", \"name='hashtags' type=<ParserChainType.HASHTAGS: 'hashtags'> llm_config=LLMConfig(llm_type='mistralai/mistral-7b-instruct', temperature='0.6') use_metadata=False max_hashtags=20\"], 'post_process_type': 'PostProcessType.COMBINED', 'openrouter_api_config': \"openrouter_api_base='https://openrouter.ai/api/v1' openrouter_api_key='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' openrouter_referer='http://localhost:3000'\", 'metadata_extract_config': \"extraction_method=<MetadataExtractionType.CITOID: 'citoid'> max_summary_length=500\"}\n",
      "+++++\n",
      "transformed_config:  {'batch_size': 5, 'wandb_config': {'entity': 'common-sense-makers', 'project': 'st-demo-sandbox'}, 'parser_configs': [{'name': 'refs_tagger', 'type': '<ParserChainType.REFERENCE_TAGGER:', 'llm_config': {'llm_type': 'mistralai/mixtral-8x7b-instruct:nitro'}, 'temperature': 0.6, 'use_metadata': True, 'is_ref': True}, {'name': 'multi_refs_tagger', 'type': '<ParserChainType.MULTI_REF_TAGGER:', 'llm_config': {'llm_type': 'mistralai/mixtral-8x7b-instruct:nitro'}, 'temperature': 0.6, 'use_metadata': True, 'is_multi_ref': True}, {'name': 'topics', 'type': '<ParserChainType.TOPICS:', 'llm_config': {'llm_type': 'mistralai/mixtral-8x7b-instruct:nitro'}, 'temperature': 0.6, 'use_metadata': True, 'is_topic': True}, {'name': 'keywords', 'type': '<ParserChainType.KEYWORDS:', 'llm_config': {'llm_type': 'mistralai/mixtral-8x7b-instruct:nitro'}, 'temperature': 0.6, 'use_metadata': True, 'max_keywords': 6}, {'name': 'hashtags', 'type': '<ParserChainType.HASHTAGS:', 'llm_config': {'llm_type': 'mistralai/mistral-7b-instruct'}, 'temperature': 0.6, 'use_metadata': False, 'max_hashtags': 20}], 'post_process_type': 'PostProcessType.COMBINED', 'openrouter_api_config': {'openrouter_api_base': 'https://openrouter.ai/api/v1', 'openrouter_api_key': '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', 'openrouter_referer': 'http://localhost:3000'}, 'metadata_extract_config': {'extraction_method': '<MetadataExtractionType.CITOID:', 'max_summary_length': 500}}\n",
      "++++++++\n",
      "OUT\n",
      "config:  {'batch_size': 5, 'wandb_config': \"entity='common-sense-makers' project='st-demo-sandbox'\", 'parser_configs': [\"name='refs_tagger' type=<ParserChainType.REFERENCE_TAGGER: 'reference_tagger'> llm_config=LLMConfig(llm_type='mistralai/mixtral-8x7b-instruct:nitro', temperature='0.6') use_metadata=True is_ref=True\", \"name='multi_refs_tagger' type=<ParserChainType.MULTI_REF_TAGGER: 'multi_reference_tagger'> llm_config=LLMConfig(llm_type='mistralai/mixtral-8x7b-instruct:nitro', temperature='0.6') use_metadata=True is_multi_ref=True\", \"name='topics' type=<ParserChainType.TOPICS: 'topics'> llm_config=LLMConfig(llm_type='mistralai/mixtral-8x7b-instruct:nitro', temperature='0.6') use_metadata=True is_topic=True\", \"name='keywords' type=<ParserChainType.KEYWORDS: 'keywords'> llm_config=LLMConfig(llm_type='mistralai/mixtral-8x7b-instruct:nitro', temperature='0.6') use_metadata=True max_keywords=6\", \"name='hashtags' type=<ParserChainType.HASHTAGS: 'hashtags'> llm_config=LLMConfig(llm_type='mistralai/mistral-7b-instruct', temperature='0.6') use_metadata=False max_hashtags=20\"], 'post_process_type': 'PostProcessType.COMBINED', 'openrouter_api_config': \"openrouter_api_base='https://openrouter.ai/api/v1' openrouter_api_key='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' openrouter_referer='http://localhost:3000'\", 'metadata_extract_config': \"extraction_method=<MetadataExtractionType.CITOID: 'citoid'> max_summary_length=500\"}\n",
      "+++++\n",
      "transformed_config:  {'batch_size': 5, 'wandb_config': {'entity': 'common-sense-makers', 'project': 'st-demo-sandbox'}, 'parser_configs': [{'name': 'refs_tagger', 'type': '<ParserChainType.REFERENCE_TAGGER:', 'llm_config': {'llm_type': 'mistralai/mixtral-8x7b-instruct:nitro'}, 'temperature': 0.6, 'use_metadata': True, 'is_ref': True}, {'name': 'multi_refs_tagger', 'type': '<ParserChainType.MULTI_REF_TAGGER:', 'llm_config': {'llm_type': 'mistralai/mixtral-8x7b-instruct:nitro'}, 'temperature': 0.6, 'use_metadata': True, 'is_multi_ref': True}, {'name': 'topics', 'type': '<ParserChainType.TOPICS:', 'llm_config': {'llm_type': 'mistralai/mixtral-8x7b-instruct:nitro'}, 'temperature': 0.6, 'use_metadata': True, 'is_topic': True}, {'name': 'keywords', 'type': '<ParserChainType.KEYWORDS:', 'llm_config': {'llm_type': 'mistralai/mixtral-8x7b-instruct:nitro'}, 'temperature': 0.6, 'use_metadata': True, 'max_keywords': 6}, {'name': 'hashtags', 'type': '<ParserChainType.HASHTAGS:', 'llm_config': {'llm_type': 'mistralai/mistral-7b-instruct'}, 'temperature': 0.6, 'use_metadata': False, 'max_hashtags': 20}], 'post_process_type': 'PostProcessType.COMBINED', 'openrouter_api_config': {'openrouter_api_base': 'https://openrouter.ai/api/v1', 'openrouter_api_key': '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', 'openrouter_referer': 'http://localhost:3000'}, 'metadata_extract_config': {'extraction_method': '<MetadataExtractionType.CITOID:', 'max_summary_length': 500}}\n",
      "++++++++\n",
      "OUT\n",
      "config:  {'batch_size': 5, 'wandb_config': \"entity='common-sense-makers' project='st-demo-sandbox'\", 'parser_configs': [\"name='refs_tagger' type=<ParserChainType.REFERENCE_TAGGER: 'reference_tagger'> llm_config=LLMConfig(llm_type='google/gemma-7b-it', temperature='0.6') use_metadata=True is_ref=True\", \"name='multi_refs_tagger' type=<ParserChainType.MULTI_REF_TAGGER: 'multi_reference_tagger'> llm_config=LLMConfig(llm_type='google/gemma-7b-it', temperature='0.6') use_metadata=True is_multi_ref=True\", \"name='topics' type=<ParserChainType.TOPICS: 'topics'> llm_config=LLMConfig(llm_type='google/gemma-7b-it', temperature='0.6') use_metadata=True is_topic=True\", \"name='keywords' type=<ParserChainType.KEYWORDS: 'keywords'> llm_config=LLMConfig(llm_type='google/gemma-7b-it', temperature='0.6') use_metadata=True max_keywords=6\", \"name='hashtags' type=<ParserChainType.HASHTAGS: 'hashtags'> llm_config=LLMConfig(llm_type='mistralai/mistral-7b-instruct', temperature='0.6') use_metadata=False max_hashtags=20\"], 'post_process_type': 'PostProcessType.COMBINED', 'openrouter_api_config': \"openrouter_api_base='https://openrouter.ai/api/v1' openrouter_api_key='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' openrouter_referer='http://localhost:3000'\", 'metadata_extract_config': \"extraction_method=<MetadataExtractionType.CITOID: 'citoid'> max_summary_length=500\"}\n",
      "+++++\n",
      "transformed_config:  {'batch_size': 5, 'wandb_config': {'entity': 'common-sense-makers', 'project': 'st-demo-sandbox'}, 'parser_configs': [{'name': 'refs_tagger', 'type': '<ParserChainType.REFERENCE_TAGGER:', 'llm_config': {'llm_type': 'google/gemma-7b-it'}, 'temperature': 0.6, 'use_metadata': True, 'is_ref': True}, {'name': 'multi_refs_tagger', 'type': '<ParserChainType.MULTI_REF_TAGGER:', 'llm_config': {'llm_type': 'google/gemma-7b-it'}, 'temperature': 0.6, 'use_metadata': True, 'is_multi_ref': True}, {'name': 'topics', 'type': '<ParserChainType.TOPICS:', 'llm_config': {'llm_type': 'google/gemma-7b-it'}, 'temperature': 0.6, 'use_metadata': True, 'is_topic': True}, {'name': 'keywords', 'type': '<ParserChainType.KEYWORDS:', 'llm_config': {'llm_type': 'google/gemma-7b-it'}, 'temperature': 0.6, 'use_metadata': True, 'max_keywords': 6}, {'name': 'hashtags', 'type': '<ParserChainType.HASHTAGS:', 'llm_config': {'llm_type': 'mistralai/mistral-7b-instruct'}, 'temperature': 0.6, 'use_metadata': False, 'max_hashtags': 20}], 'post_process_type': 'PostProcessType.COMBINED', 'openrouter_api_config': {'openrouter_api_base': 'https://openrouter.ai/api/v1', 'openrouter_api_key': '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', 'openrouter_referer': 'http://localhost:3000'}, 'metadata_extract_config': {'extraction_method': '<MetadataExtractionType.CITOID:', 'max_summary_length': 500}}\n",
      "++++++++\n",
      "OUT\n",
      "config:  {}\n",
      "+++++\n",
      "transformed_config:  {}\n",
      "++++++++\n",
      "'parser_configs'\n",
      "config:  {}\n",
      "+++++\n",
      "transformed_config:  {}\n",
      "++++++++\n",
      "'parser_configs'\n",
      "config:  {}\n",
      "+++++\n",
      "transformed_config:  {}\n",
      "++++++++\n",
      "'parser_configs'\n",
      "config:  {}\n",
      "+++++\n",
      "transformed_config:  {}\n",
      "++++++++\n",
      "'parser_configs'\n",
      "config:  {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'wandb': {'entity': 'common-sense-makers', 'project': None}, 'general': {'parser_type': 'multi_stage', 'max_summary_length': 500, 'ref_metadata_method': 'none'}, 'ontology': {'versions': None, 'notion_db_id': None}, 'openai_api': {'openai_api_key': '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', 'openai_api_base': 'https://openrouter.ai/api/v1', 'openai_api_referer': 'http://localhost:3000'}, 'keyword_extraction': {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'enabled': True, 'template': 'keywords_extraction.j2', 'max_keywords': 6, 'ref_metadata_method': 'citoid'}}\n",
      "+++++\n",
      "transformed_config:  {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'wandb': {'entity': 'common-sense-makers', 'project': None}, 'general': {'parser_type': 'multi_stage', 'max_summary_length': 500, 'ref_metadata_method': 'none'}, 'ontology': {'versions': None, 'notion_db_id': None}, 'openai_api': {'openai_api_key': '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', 'openai_api_base': 'https://openrouter.ai/api/v1', 'openai_api_referer': 'http://localhost:3000'}, 'keyword_extraction': {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'enabled': True, 'template': 'keywords_extraction.j2', 'max_keywords': 6, 'ref_metadata_method': 'citoid'}}\n",
      "++++++++\n",
      "'parser_configs'\n",
      "config:  {}\n",
      "+++++\n",
      "transformed_config:  {}\n",
      "++++++++\n",
      "'parser_configs'\n",
      "config:  {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'wandb': {'entity': 'common-sense-makers', 'project': None}, 'general': {'parser_type': 'multi_stage', 'max_summary_length': 500, 'ref_metadata_method': 'none'}, 'ontology': {'versions': None, 'notion_db_id': None}, 'openai_api': {'openai_api_key': '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', 'openai_api_base': 'https://openrouter.ai/api/v1', 'openai_api_referer': 'http://localhost:3000'}, 'keyword_extraction': {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'enabled': True, 'template': 'keywords_extraction.j2', 'max_keywords': 6, 'ref_metadata_method': 'citoid'}}\n",
      "+++++\n",
      "transformed_config:  {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'wandb': {'entity': 'common-sense-makers', 'project': None}, 'general': {'parser_type': 'multi_stage', 'max_summary_length': 500, 'ref_metadata_method': 'none'}, 'ontology': {'versions': None, 'notion_db_id': None}, 'openai_api': {'openai_api_key': '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', 'openai_api_base': 'https://openrouter.ai/api/v1', 'openai_api_referer': 'http://localhost:3000'}, 'keyword_extraction': {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'enabled': True, 'template': 'keywords_extraction.j2', 'max_keywords': 6, 'ref_metadata_method': 'citoid'}}\n",
      "++++++++\n",
      "'parser_configs'\n",
      "config:  {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'wandb': {'entity': 'common-sense-makers', 'project': None}, 'general': {'parser_type': 'multi_stage', 'max_summary_length': 500, 'ref_metadata_method': 'none'}, 'ontology': {'versions': None, 'notion_db_id': None}, 'openai_api': {'openai_api_key': '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', 'openai_api_base': 'https://openrouter.ai/api/v1', 'openai_api_referer': 'http://localhost:3000'}, 'keyword_extraction': {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'enabled': True, 'template': 'keywords_extraction.j2', 'max_keywords': 6, 'ref_metadata_method': 'citoid'}}\n",
      "+++++\n",
      "transformed_config:  {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'wandb': {'entity': 'common-sense-makers', 'project': None}, 'general': {'parser_type': 'multi_stage', 'max_summary_length': 500, 'ref_metadata_method': 'none'}, 'ontology': {'versions': None, 'notion_db_id': None}, 'openai_api': {'openai_api_key': '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', 'openai_api_base': 'https://openrouter.ai/api/v1', 'openai_api_referer': 'http://localhost:3000'}, 'keyword_extraction': {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'enabled': True, 'template': 'keywords_extraction.j2', 'max_keywords': 6, 'ref_metadata_method': 'citoid'}}\n",
      "++++++++\n",
      "'parser_configs'\n",
      "config:  {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'wandb': {'entity': 'common-sense-makers', 'project': None}, 'general': {'parser_type': 'multi_stage', 'max_summary_length': 500, 'ref_metadata_method': 'none'}, 'ontology': {'versions': None, 'notion_db_id': None}, 'openai_api': {'openai_api_key': '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', 'openai_api_base': 'https://openrouter.ai/api/v1', 'openai_api_referer': 'http://localhost:3000'}, 'keyword_extraction': {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'enabled': True, 'template': 'keywords_extraction.j2', 'max_keywords': 6, 'ref_metadata_method': 'citoid'}}\n",
      "+++++\n",
      "transformed_config:  {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'wandb': {'entity': 'common-sense-makers', 'project': None}, 'general': {'parser_type': 'multi_stage', 'max_summary_length': 500, 'ref_metadata_method': 'none'}, 'ontology': {'versions': None, 'notion_db_id': None}, 'openai_api': {'openai_api_key': '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', 'openai_api_base': 'https://openrouter.ai/api/v1', 'openai_api_referer': 'http://localhost:3000'}, 'keyword_extraction': {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'enabled': True, 'template': 'keywords_extraction.j2', 'max_keywords': 6, 'ref_metadata_method': 'citoid'}}\n",
      "++++++++\n",
      "'parser_configs'\n",
      "config:  {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'wandb': {'entity': 'common-sense-makers', 'project': None}, 'general': {'parser_type': 'multi_stage', 'max_summary_length': 500, 'ref_metadata_method': 'none'}, 'ontology': {'versions': None, 'notion_db_id': None}, 'openai_api': {'openai_api_key': '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', 'openai_api_base': 'https://openrouter.ai/api/v1', 'openai_api_referer': 'http://localhost:3000'}, 'keyword_extraction': {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'enabled': True, 'template': 'keywords_extraction.j2', 'max_keywords': 6, 'ref_metadata_method': 'citoid'}}\n",
      "+++++\n",
      "transformed_config:  {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'wandb': {'entity': 'common-sense-makers', 'project': None}, 'general': {'parser_type': 'multi_stage', 'max_summary_length': 500, 'ref_metadata_method': 'none'}, 'ontology': {'versions': None, 'notion_db_id': None}, 'openai_api': {'openai_api_key': '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', 'openai_api_base': 'https://openrouter.ai/api/v1', 'openai_api_referer': 'http://localhost:3000'}, 'keyword_extraction': {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'enabled': True, 'template': 'keywords_extraction.j2', 'max_keywords': 6, 'ref_metadata_method': 'citoid'}}\n",
      "++++++++\n",
      "'parser_configs'\n",
      "config:  {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'wandb': {'entity': 'common-sense-makers', 'project': None}, 'general': {'parser_type': 'multi_stage', 'max_summary_length': 500, 'ref_metadata_method': 'none'}, 'ontology': {'versions': None, 'notion_db_id': None}, 'openai_api': {'openai_api_key': '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', 'openai_api_base': 'https://openrouter.ai/api/v1', 'openai_api_referer': 'http://localhost:3000'}, 'keyword_extraction': {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'enabled': True, 'template': 'keywords_extraction.j2', 'max_keywords': 6, 'ref_metadata_method': 'citoid'}}\n",
      "+++++\n",
      "transformed_config:  {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'wandb': {'entity': 'common-sense-makers', 'project': None}, 'general': {'parser_type': 'multi_stage', 'max_summary_length': 500, 'ref_metadata_method': 'none'}, 'ontology': {'versions': None, 'notion_db_id': None}, 'openai_api': {'openai_api_key': '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', 'openai_api_base': 'https://openrouter.ai/api/v1', 'openai_api_referer': 'http://localhost:3000'}, 'keyword_extraction': {'model': {'model_name': 'mistralai/mistral-7b-instruct', 'temperature': 0.6}, 'enabled': True, 'template': 'keywords_extraction.j2', 'max_keywords': 6, 'ref_metadata_method': 'citoid'}}\n",
      "++++++++\n",
      "'parser_configs'\n",
      "All runs have been updated.\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import json\n",
    "\n",
    "\n",
    "# Ensure you're logged into W&B\n",
    "wandb.login()\n",
    "\n",
    "# Set your project and entity names\n",
    "project_name = 'filter_evaluation'\n",
    "entity_name = 'common-sense-makers'\n",
    "\n",
    "# Retrieve all runs in the project\n",
    "api = wandb.Api()\n",
    "runs = api.runs(f\"{entity_name}/{project_name}\")\n",
    "\n",
    "# Iterate through each run and apply the transformation\n",
    "for run in runs:\n",
    "    # Retrieve the current configuration\n",
    "    config = dict(run.config)\n",
    "    print('config: ',config)\n",
    "    print('+++++')\n",
    "    \n",
    "    # Apply the transformation\n",
    "    transformed_config = obj_to_dict(config)\n",
    "    print('transformed_config: ', transformed_config)\n",
    "    print('++++++++')\n",
    "    # Update the run configuration\n",
    "    try: \n",
    "        run.config.clear()\n",
    "        run.config['llm_config']=transformed_config['parser_configs'][0]['llm_config']\n",
    "        print('OUT')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    # Optionally, save the updated run (Note: wandb.run object must be used with `wandb.init`)\n",
    "    # run.update() # This is just a placeholder, not an actual method\n",
    "\n",
    "# Print a message when done\n",
    "print(\"All runs have been updated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = obj_to_dict({'batch_size': 5, 'wandb_config': \"entity='common-sense-makers' project='st-demo-sandbox'\", 'parser_configs': [\"name='refs_tagger' type=<ParserChainType.REFERENCE_TAGGER: 'reference_tagger'> llm_config=LLMConfig(llm_type='google/gemma-7b-it:nitro', temperature='0.6') use_metadata=True is_ref=True\", \"name='multi_refs_tagger' type=<ParserChainType.MULTI_REF_TAGGER: 'multi_reference_tagger'> llm_config=LLMConfig(llm_type='google/gemma-7b-it:nitro', temperature='0.6') use_metadata=True is_multi_ref=True\", \"name='topics' type=<ParserChainType.TOPICS: 'topics'> llm_config=LLMConfig(llm_type='google/gemma-7b-it:nitro', temperature='0.6') use_metadata=True is_topic=True\", \"name='keywords' type=<ParserChainType.KEYWORDS: 'keywords'> llm_config=LLMConfig(llm_type='google/gemma-7b-it:nitro', temperature='0.6') use_metadata=True max_keywords=6\", \"name='hashtags' type=<ParserChainType.HASHTAGS: 'hashtags'> llm_config=LLMConfig(llm_type='mistralai/mistral-7b-instruct', temperature='0.6') use_metadata=False max_hashtags=20\"], 'post_process_type': 'PostProcessType.COMBINED', 'openrouter_api_config': \"openrouter_api_base='https://openrouter.ai/api/v1' openrouter_api_key='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' openrouter_referer='http://localhost:3000'\", 'metadata_extract_config': \"extraction_method=<MetadataExtractionType.CITOID: 'citoid'> max_summary_length=500\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'llm_type': 'google/gemma-7b-it:nitro'}\n"
     ]
    }
   ],
   "source": [
    "print(ex['parser_configs'][0]['llm_config'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random parser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have a DataFrame 'df' with your true labels\n",
    "true_labels = df['True Label']\n",
    "\n",
    "#Generate random predictions\n",
    "np.random.seed(42)  # For reproducibility\n",
    "random_predictions = np.random.choice(['research', 'not_research'], size=len(true_labels))\n",
    "\n",
    "\n",
    "# Add these random predictions to the DataFrame\n",
    "df['Predicted Label'] = random_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:g39xcxp1) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51cb4191a28c43dd86814a512c395908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">curious-valley-242</strong> at: <a href='https://wandb.ai/common-sense-makers/testing/runs/g39xcxp1' target=\"_blank\">https://wandb.ai/common-sense-makers/testing/runs/g39xcxp1</a><br/> View project at: <a href='https://wandb.ai/common-sense-makers/testing' target=\"_blank\">https://wandb.ai/common-sense-makers/testing</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240520_193247-g39xcxp1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:g39xcxp1). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/shaharorielkagan/sensemakers/nlp/notebooks/wandb/run-20240522_143906-i2vw06cj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/common-sense-makers/filter_evaluation/runs/i2vw06cj' target=\"_blank\">earnest-firebrand-58</a></strong> to <a href='https://wandb.ai/common-sense-makers/filter_evaluation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/common-sense-makers/filter_evaluation' target=\"_blank\">https://wandb.ai/common-sense-makers/filter_evaluation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/common-sense-makers/filter_evaluation/runs/i2vw06cj' target=\"_blank\">https://wandb.ai/common-sense-makers/filter_evaluation/runs/i2vw06cj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9341e81d3264e74a42ddb0e6f79c959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">earnest-firebrand-58</strong> at: <a href='https://wandb.ai/common-sense-makers/filter_evaluation/runs/i2vw06cj' target=\"_blank\">https://wandb.ai/common-sense-makers/filter_evaluation/runs/i2vw06cj</a><br/> View project at: <a href='https://wandb.ai/common-sense-makers/filter_evaluation' target=\"_blank\">https://wandb.ai/common-sense-makers/filter_evaluation</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240522_143906-i2vw06cj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import bad prediction table\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "#TODO move from testing\n",
    "run = wandb.init(project=\"filter_evaluation\", job_type=\"evaluation\")\n",
    "dataset_artifact_id = (\n",
    "        'common-sense-makers/filter_evaluation/prediction_evaluation-20240521132713:v0'\n",
    "    )\n",
    "dataset_artifact = run.use_artifact(dataset_artifact_id)\n",
    "\n",
    "a_path = dataset_artifact.download()\n",
    "\n",
    "# get handle file name\n",
    "\n",
    "table_path = Path(f\"{a_path}/prediction_evaluation.table.json\")\n",
    "\n",
    "dataset_run = dataset_artifact.logged_by()\n",
    "\n",
    "config = dataset_run.config\n",
    "\n",
    "df = get_dataset(table_path)\n",
    "\n",
    "wandb.run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = set(df2.columns) - set(df.columns)\n",
    "for key in keys:\n",
    "    df[key] = df2[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['random_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 4) (2338372753.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[41], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    pattern = re.compile(r'^https://twitter\\')\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 4)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def check_twitter_urls(urls):\n",
    "    pattern = re.compile(r'^https://twitter\\.com/.+/[0-9]+$')\n",
    "    for url in urls:\n",
    "        if pattern.match(url):\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_twitter_urls(urls):\n",
    "    for url in urls:\n",
    "        if url.startswith(\"https://twitter.com/\"):\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n =0\n",
    "for urls in df['urls']:\n",
    "    n = n+check_twitter_urls(urls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13232104121475055\n"
     ]
    }
   ],
   "source": [
    "print(n/461)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meet = df[df[\"Predicted Label\"]==df[\"True Label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = df[df[\"Predicted Label\"] != df['True Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Quote of the Day, April 15, 2024;\n",
      "\n",
      "Three more quotes chosen by Jose Ramos:\n",
      "\n",
      "\"We‚Äôve lived so long under the spell of hierarchy‚Äîfrom god-kings to feudal lords to party bosses‚Äîthat only recently have we awakened to see not only that ‚Äúregular‚Äù citizens have the capacity for self-governance, but that without their engagement our huge global crises cannot be addressed. The changes needed for human society simply to survive, let alone thrive, are so profound that the only way we will move toward them is if we ourselves, regular citizens, feel meaningful ownership of solutions through direct engagement. Our problems are too big, interrelated, and pervasive to yield to directives from on high.\"\n",
      "\n",
      "‚ÄîFrances Moore Lapp√©, Time for Progressives to Grow Up \n",
      "\n",
      "Someone who has been immersed in orthodoxy needs to experience a figureground reversal in order to gain perspective. This can‚Äôt come from encountering just a few heterodox thoughts, but only from a new encompassing architecture of interconnected thoughts that can engulf a person with a different worldview.\n",
      "\n",
      "- Jaron Lanier \n",
      "\n",
      "There are periods in human existence when the inevitability of a great upheaval, of a cataclysm that shakes society to its very roots, imposes itself on every area of our relationships. At such epochs, all people of good will begin to realize that things cannot go on as they are; that we need great events that roughly break the thread of history, shake humanity out of the ruts in which it is stuck and propel it toward new ways, toward the unknown . . .‚Äù\n",
      "\n",
      "- Pyotr Kropotkin, Keywords: ['Transformation', 'SocietalChange', 'Philosophy', 'PerspectiveShift', 'Revolution', 'SelfGovernance'] Topics: ['philosophy', 'politics', 'culture']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Text: {df_diff['Text'][18]}, Keywords: {df_diff['Keywords'][18]} Topics: {df_diff['Topics'][18]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_types_whitelist = [\n",
    "    \"bookSection\",\n",
    "    \"journalArticle\",\n",
    "    \"preprint\",\n",
    "    \"book\",\n",
    "    \"manuscript\",\n",
    "    \"thesis\",\n",
    "    \"presentation\",\n",
    "    \"conferencePaper\",\n",
    "    \"report\",\n",
    "]\n",
    "\n",
    "\n",
    "topics_whitelist = [\n",
    "    \"technology\",\n",
    "    \"science\",\n",
    "    \"academia\",\n",
    "    \"research\",\n",
    "    \"design\",\n",
    "    \"climate\",\n",
    "    \"sustainability\",\n",
    "    \"software & hardware\",\n",
    "    \"philosophy\",\n",
    "    \"health\",\n",
    "    \"culture\",\n",
    "    \"economics\",\n",
    "    \"business\",\n",
    "    \"finance\",\n",
    "    \"literature\",\n",
    "]\n",
    "\n",
    "\n",
    "def apply_research_filter_keywords_down(row):\n",
    "    # if any item types on the whitelist, pass automatically\n",
    "    if len(set(row['Ref item types']).intersection(set(item_types_whitelist))) > 0:\n",
    "        return 'research'\n",
    "\n",
    "    # if item types inconclusive, use scoring system\n",
    "    score = 0\n",
    "\n",
    "    # if research related topics not present = 1 point\n",
    "    if len(set(row['Topics']).intersection(set(topics_whitelist))) == 0:\n",
    "        score += 2\n",
    "\n",
    "\n",
    "    # if no references present = 1 point\n",
    "    if row['ref_count'] == 0:\n",
    "        score += 1\n",
    "\n",
    "    if score >= 2:\n",
    "        return 'not_research'\n",
    "    else:\n",
    "        return 'reaserch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df\n",
    "df1['Predicted Label'] = df1.apply(lambda row: apply_research_filter_keywords_down(row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'academic'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].research_keyword"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

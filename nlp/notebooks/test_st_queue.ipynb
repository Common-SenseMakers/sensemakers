{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "from mastodon import Mastodon\n",
    "from datetime import datetime, time\n",
    "\n",
    "from desci_sense.shared_functions.schema.post import RefPost\n",
    "from desci_sense.shared_functions.postprocessing import StreamlitParserResults\n",
    "from desci_sense.shared_functions.postprocessing.output_parsers import AllowedTermsParser, ALLOWED_TAGS_DELIMITER\n",
    "from desci_sense.shared_functions.utils import flatten\n",
    "from desci_sense.shared_functions.web_extractors.metadata_extractors import (extract_all_metadata_by_type, MetadataExtractionType, RefMetadata, extract_all_metadata_to_dict,)\n",
    "from desci_sense.shared_functions.dataloaders.mastodon.mastodon_loader import MastodonLoader\n",
    "\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "from desci_sense.configs import default_init_parser_config\n",
    "from desci_sense.shared_functions.dataloaders import scrape_post\n",
    "from desci_sense.shared_functions.parsers.firebase_api_parser import FirebaseAPIParser, PromptCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = datetime(2024, 1, 1)\n",
    "end_date = datetime(2024, 1, 30)\n",
    "mloader = MastodonLoader()\n",
    "acct = \"@ronent@mastodon.social\"\n",
    "posts = mloader.load_profile_timeline(\n",
    "    acct,\n",
    "    max_toots=30,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    exclude_replies=True,\n",
    "    exclude_reposts=True,\n",
    ")\n",
    "len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = default_init_parser_config(semantics_model=\"mistralai/mistral-7b-instruct\",\n",
    "                                    kw_model=\"mistralai/mistral-7b-instruct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-19 19:01:03.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.firebase_api_parser\u001b[0m:\u001b[36mset_md_extract_method\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1mSetting metadata extraction method to none...\u001b[0m\n",
      "\u001b[32m2024-03-19 19:01:03.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.firebase_api_parser\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m115\u001b[0m - \u001b[1mLoading parser model (type=mistralai/mistral-7b-instruct)...\u001b[0m\n",
      "\u001b[32m2024-03-19 19:01:03.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.firebase_api_parser\u001b[0m:\u001b[36mset_kw_md_extract_method\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mSetting keywords metadata extraction method to citoid...\u001b[0m\n",
      "\u001b[32m2024-03-19 19:01:03.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.firebase_api_parser\u001b[0m:\u001b[36minit_keyword_extraction_chain\u001b[0m:\u001b[36m449\u001b[0m - \u001b[1mLoading keyword model (type=mistralai/mistral-7b-instruct)...\u001b[0m\n",
      "\u001b[32m2024-03-19 19:01:03.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.firebase_api_parser\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m132\u001b[0m - \u001b[1mLoading ontology...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "parser = FirebaseAPIParser(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-19 19:01:06.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.firebase_api_parser\u001b[0m:\u001b[36mset_md_extract_method\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1mSetting metadata extraction method to citoid...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "parser.set_md_extract_method(\"citoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-19 19:01:09.916\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async\u001b[0m:\u001b[36m20\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://paragraph.xyz/@sense-nets/sense-nets-intro\u001b[0m\n",
      "\u001b[32m2024-03-19 19:01:09.916\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async\u001b[0m:\u001b[36m20\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://paragraph.xyz/@sense-nets/2-project-plan\u001b[0m\n",
      "\u001b[32m2024-03-19 19:01:09.917\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async\u001b[0m:\u001b[36m20\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://arxiv.org/abs/2401.13782\u001b[0m\n",
      "\u001b[32m2024-03-19 19:01:09.917\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdesci_sense.shared_functions.web_extractors.citoid\u001b[0m:\u001b[36mfetch_citation_async\u001b[0m:\u001b[36m20\u001b[0m - \u001b[34m\u001b[1mtarget_url=https://twitter.com/deliprao/status/1750732070014337101\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = await parser.abatch_process_ref_post(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_posts_to_df(posts: List[RefPost]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Renders posts as dataframe with columns `author`, `url`, `content`, and `created_at` fields.\n",
    "    \"\"\"\n",
    "    # Create a list of dictionaries, each representing a row in the resulting DataFrame\n",
    "    data = [\n",
    "        {\n",
    "            \"author\": post.author,\n",
    "            \"content\": post.content,\n",
    "            \"url\": post.url,\n",
    "            \"created_at\": post.created_at,\n",
    "        }\n",
    "        for post in posts\n",
    "    ]\n",
    "\n",
    "    # Convert the list of dictionaries into a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ronen Tamari</td>\n",
       "      <td>Also relevant for discussions about science so...</td>\n",
       "      <td>https://mastodon.social/@ronent/11182257120421...</td>\n",
       "      <td>2024-01-26 13:50:26.443000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ronen Tamari</td>\n",
       "      <td>*crosspost from birdsite*  \\nNew year, new way...</td>\n",
       "      <td>https://mastodon.social/@ronent/11168703832254...</td>\n",
       "      <td>2024-01-02 15:22:38.781000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author                                            content  \\\n",
       "0  Ronen Tamari  Also relevant for discussions about science so...   \n",
       "1  Ronen Tamari  *crosspost from birdsite*  \\nNew year, new way...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://mastodon.social/@ronent/11182257120421...   \n",
       "1  https://mastodon.social/@ronent/11168703832254...   \n",
       "\n",
       "                        created_at  \n",
       "0 2024-01-26 13:50:26.443000+00:00  \n",
       "1 2024-01-02 15:22:38.781000+00:00  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = render_posts_to_df(posts)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>created_at</th>\n",
       "      <th>science_filter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ronen Tamari</td>\n",
       "      <td>Also relevant for discussions about science so...</td>\n",
       "      <td>https://mastodon.social/@ronent/11182257120421...</td>\n",
       "      <td>2024-01-26 13:50:26.443000+00:00</td>\n",
       "      <td>not-detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ronen Tamari</td>\n",
       "      <td>*crosspost from birdsite*  \\nNew year, new way...</td>\n",
       "      <td>https://mastodon.social/@ronent/11168703832254...</td>\n",
       "      <td>2024-01-02 15:22:38.781000+00:00</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author                                            content  \\\n",
       "0  Ronen Tamari  Also relevant for discussions about science so...   \n",
       "1  Ronen Tamari  *crosspost from birdsite*  \\nNew year, new way...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://mastodon.social/@ronent/11182257120421...   \n",
       "1  https://mastodon.social/@ronent/11168703832254...   \n",
       "\n",
       "                        created_at science_filter  \n",
       "0 2024-01-26 13:50:26.443000+00:00   not-detected  \n",
       "1 2024-01-02 15:22:38.781000+00:00       academic  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"science_filter\"] = [r.research_filter for r in results]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"reference_urls\"] = [r.reference_urls for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>created_at</th>\n",
       "      <th>science_filter</th>\n",
       "      <th>research_filter</th>\n",
       "      <th>item_types</th>\n",
       "      <th>reference_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ronen Tamari</td>\n",
       "      <td>Also relevant for discussions about science so...</td>\n",
       "      <td>https://mastodon.social/@ronent/11182257120421...</td>\n",
       "      <td>2024-01-26 13:50:26.443000+00:00</td>\n",
       "      <td>not-detected</td>\n",
       "      <td>not-detected</td>\n",
       "      <td>nan</td>\n",
       "      <td>[https://arxiv.org/abs/2401.13782, https://twi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ronen Tamari</td>\n",
       "      <td>*crosspost from birdsite*  \\nNew year, new way...</td>\n",
       "      <td>https://mastodon.social/@ronent/11168703832254...</td>\n",
       "      <td>2024-01-02 15:22:38.781000+00:00</td>\n",
       "      <td>academic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>[https://paragraph.xyz/@sense-nets/sense-nets-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author                                            content  \\\n",
       "0  Ronen Tamari  Also relevant for discussions about science so...   \n",
       "1  Ronen Tamari  *crosspost from birdsite*  \\nNew year, new way...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://mastodon.social/@ronent/11182257120421...   \n",
       "1  https://mastodon.social/@ronent/11168703832254...   \n",
       "\n",
       "                        created_at science_filter research_filter item_types  \\\n",
       "0 2024-01-26 13:50:26.443000+00:00   not-detected    not-detected        nan   \n",
       "1 2024-01-02 15:22:38.781000+00:00       academic             NaN        nan   \n",
       "\n",
       "                                      reference_urls  \n",
       "0  [https://arxiv.org/abs/2401.13782, https://twi...  \n",
       "1  [https://paragraph.xyz/@sense-nets/sense-nets-...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_results_to_df(df: pd.DataFrame, results: List[StreamlitParserResults]) -> pd.DataFrame:\n",
    "    # \"\"\"\n",
    "    # Add columns to the dataframe `df` corresponding to each `StreamlitParserResults` field.\n",
    "    # Each row in `results` corresponds to a row in `df` and should extend it by adding those columns\n",
    "    # \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_results_to_df(df: pd.DataFrame, results: List[StreamlitParserResults]) -> pd.DataFrame:\n",
    "    # Check if df is not empty and has the same number of rows as the length of results\n",
    "    if not df.empty and len(df) == len(results):\n",
    "        # Iterate through each result and the corresponding index\n",
    "        for idx, result in enumerate(results):\n",
    "            # For each attribute in result, add it as a new column in df\n",
    "            for field in result.model_dump().keys():\n",
    "                if field != \"debug\":\n",
    "                    df.loc[idx, field] = result.model_dump()[field]\n",
    "    else:\n",
    "        # Handling case where df is empty or row counts do not match\n",
    "        # This could be an error or you might want to append rows based on results\n",
    "        raise ValueError(\"DataFrame is empty or does not match the number of results provided.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m new_df \u001b[38;5;241m=\u001b[39m \u001b[43madd_results_to_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 9\u001b[0m, in \u001b[0;36madd_results_to_df\u001b[0;34m(df, results)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mmodel_dump()\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      8\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m field \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdebug\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 9\u001b[0m                 \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mmodel_dump()[field]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Handling case where df is empty or row counts do not match\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# This could be an error or you might want to append rows based on results\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame is empty or does not match the number of results provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/asensebot/lib/python3.11/site-packages/pandas/core/indexing.py:912\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    911\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 912\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/asensebot/lib/python3.11/site-packages/pandas/core/indexing.py:1894\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key] \u001b[38;5;241m=\u001b[39m infer_fill_value(value)\n\u001b[1;32m   1891\u001b[0m     new_indexer \u001b[38;5;241m=\u001b[39m convert_from_missing_indexer_tuple(\n\u001b[1;32m   1892\u001b[0m         indexer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39maxes\n\u001b[1;32m   1893\u001b[0m     )\n\u001b[0;32m-> 1894\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1898\u001b[0m \u001b[38;5;66;03m# reindex the axis\u001b[39;00m\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;66;03m# make sure to clear the cache because we are\u001b[39;00m\n\u001b[1;32m   1900\u001b[0m \u001b[38;5;66;03m# just replacing the block manager here\u001b[39;00m\n\u001b[1;32m   1901\u001b[0m \u001b[38;5;66;03m# so the object is the same\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/asensebot/lib/python3.11/site-packages/pandas/core/indexing.py:1946\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1943\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[1;32m   1944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[1;32m   1945\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[0;32m-> 1946\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_split_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1948\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[0;32m~/anaconda3/envs/asensebot/lib/python3.11/site-packages/pandas/core/indexing.py:2002\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1997\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_integer(info_axis):\n\u001b[1;32m   1998\u001b[0m         \u001b[38;5;66;03m# This is a case like df.iloc[:3, [1]] = [0]\u001b[39;00m\n\u001b[1;32m   1999\u001b[0m         \u001b[38;5;66;03m#  where we treat as df.iloc[:3, 1] = 0\u001b[39;00m\n\u001b[1;32m   2000\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer((pi, info_axis[\u001b[38;5;241m0\u001b[39m]), value[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2002\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2003\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust have equal len keys and value \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2004\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen setting with an iterable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2005\u001b[0m     )\n\u001b[1;32m   2007\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lplane_indexer \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m   2008\u001b[0m     \u001b[38;5;66;03m# We get here in one case via .loc with a all-False mask\u001b[39;00m\n\u001b[1;32m   2009\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Must have equal len keys and value when setting with an iterable"
     ]
    }
   ],
   "source": [
    "new_df = add_results_to_df(df, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_results_to_df(df: pd.DataFrame, results: List[StreamlitParserResults]) -> pd.DataFrame:\n",
    "    # Ensure the DataFrame and results list have the same length\n",
    "    if not df.empty and len(df) == len(results):\n",
    "        # Iterate over the schema of StreamlitParserResults to get all field names\n",
    "        for field_name in StreamlitParserResults.model_fields.keys():\n",
    "            if field_name != \"debug\":\n",
    "                # For each field, create a new column in df with the values from results\n",
    "                df[field_name] = [getattr(r, field_name) for r in results]\n",
    "    else:\n",
    "        raise ValueError(\"DataFrame is empty or does not match the number of results provided.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>created_at</th>\n",
       "      <th>science_filter</th>\n",
       "      <th>research_filter</th>\n",
       "      <th>item_types</th>\n",
       "      <th>reference_urls</th>\n",
       "      <th>semantic_tags</th>\n",
       "      <th>keywords</th>\n",
       "      <th>debug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ronen Tamari</td>\n",
       "      <td>Also relevant for discussions about science so...</td>\n",
       "      <td>https://mastodon.social/@ronent/11182257120421...</td>\n",
       "      <td>2024-01-26 13:50:26.443000+00:00</td>\n",
       "      <td>not-detected</td>\n",
       "      <td>not-detected</td>\n",
       "      <td>[preprint, unknown]</td>\n",
       "      <td>[https://arxiv.org/abs/2401.13782, https://twi...</td>\n",
       "      <td>[discussion]</td>\n",
       "      <td>[citation-counts, nanopub, social-media, resea...</td>\n",
       "      <td>{'semantics': {'prompt': '\n",
       "You are an expert a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ronen Tamari</td>\n",
       "      <td>*crosspost from birdsite*  \\nNew year, new way...</td>\n",
       "      <td>https://mastodon.social/@ronent/11168703832254...</td>\n",
       "      <td>2024-01-02 15:22:38.781000+00:00</td>\n",
       "      <td>academic</td>\n",
       "      <td>academic</td>\n",
       "      <td>[webpage, webpage]</td>\n",
       "      <td>[https://paragraph.xyz/@sense-nets/sense-nets-...</td>\n",
       "      <td>[call-for-papers]</td>\n",
       "      <td>[FragmentedScienceSocialMedia, ScienceSocialMe...</td>\n",
       "      <td>{'semantics': {'prompt': '\n",
       "You are an expert a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author                                            content  \\\n",
       "0  Ronen Tamari  Also relevant for discussions about science so...   \n",
       "1  Ronen Tamari  *crosspost from birdsite*  \\nNew year, new way...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://mastodon.social/@ronent/11182257120421...   \n",
       "1  https://mastodon.social/@ronent/11168703832254...   \n",
       "\n",
       "                        created_at science_filter research_filter  \\\n",
       "0 2024-01-26 13:50:26.443000+00:00   not-detected    not-detected   \n",
       "1 2024-01-02 15:22:38.781000+00:00       academic        academic   \n",
       "\n",
       "            item_types                                     reference_urls  \\\n",
       "0  [preprint, unknown]  [https://arxiv.org/abs/2401.13782, https://twi...   \n",
       "1   [webpage, webpage]  [https://paragraph.xyz/@sense-nets/sense-nets-...   \n",
       "\n",
       "       semantic_tags                                           keywords  \\\n",
       "0       [discussion]  [citation-counts, nanopub, social-media, resea...   \n",
       "1  [call-for-papers]  [FragmentedScienceSocialMedia, ScienceSocialMe...   \n",
       "\n",
       "                                               debug  \n",
       "0  {'semantics': {'prompt': '\n",
       "You are an expert a...  \n",
       "1  {'semantics': {'prompt': '\n",
       "You are an expert a...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = add_results_to_df(df, results)\n",
    "new_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asensebot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
